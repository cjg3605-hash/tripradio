/**
 * ë‹¤ì¤‘ í™”ì TTS ìƒì„± ì‹œìŠ¤í…œ
 * í™”ìë³„ë¡œ ë‹¤ë¥¸ ìŒì„±ìœ¼ë¡œ ëŒ€í™”ë¥¼ ìƒì„±í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íš¨ê³¼ êµ¬í˜„
 */

import { SpeakerSegment, VoiceStyle } from './notebooklm-script-cleaner';

export interface MultiVoiceTTSConfig {
  /** í™”ìë³„ ìŒì„± ì„¤ì • */
  voiceMapping: VoiceMappingConfig;
  /** ìŒì„± í’ˆì§ˆ ì„¤ì • */
  audioQuality: AudioQualityConfig;
  /** ëŒ€í™” íë¦„ ìµœì í™” */
  conversationFlow: ConversationFlowConfig;
  /** ì¶œë ¥ í˜•ì‹ */
  outputFormat: OutputFormatConfig;
}

export interface VoiceMappingConfig {
  /** ì§„í–‰ì ìŒì„± ì„¤ì • */
  host: VoiceConfig;
  /** íë ˆì´í„° ìŒì„± ì„¤ì • */
  curator: VoiceConfig;
  /** í™”ì ê°„ ìŒì„± ì°¨ë³„í™” ê°•ë„ */
  differentiationLevel: 'subtle' | 'moderate' | 'distinct';
}

export interface VoiceConfig {
  /** Google Cloud TTS ìŒì„± ì´ë¦„ */
  voiceName: string;
  /** ì–¸ì–´ ì½”ë“œ */
  languageCode: string;
  /** ì„±ë³„ */
  ssmlGender: 'MALE' | 'FEMALE' | 'NEUTRAL';
  /** ë§í•˜ê¸° ì†ë„ */
  speakingRate: number; // 0.25 ~ 4.0
  /** í”¼ì¹˜ ì¡°ì ˆ */
  pitch: number; // -20.0 ~ 20.0
  /** ë³¼ë¥¨ ê²Œì¸ */
  volumeGainDb: number; // -96.0 ~ 16.0
  /** ìŒì„± í”„ë¡œíŒŒì¼ */
  effects?: AudioEffect[];
}

export interface AudioEffect {
  /** íš¨ê³¼ íƒ€ì… */
  type: 'telephony' | 'handset' | 'headphone' | 'small_bluetooth_speaker' | 'medium_bluetooth_speaker' | 'large_home_entertainment' | 'large_automotive' | 'wearable';
}

export interface AudioQualityConfig {
  /** ì˜¤ë””ì˜¤ ì¸ì½”ë”© */
  encoding: 'LINEAR16' | 'MP3' | 'OGG_OPUS';
  /** ìƒ˜í”Œ ë ˆì´íŠ¸ */
  sampleRateHertz: number; // 8000, 16000, 22050, 24000, 44100, 48000
  /** ë¹„íŠ¸ë ˆì´íŠ¸ (MP3ìš©) */
  bitrate?: number; // 32000 ~ 320000
}

export interface ConversationFlowConfig {
  /** í™”ì ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ê°„ê²© (ms) */
  speakerTransitionDelay: number;
  /** ë¬¸ì¥ ë íœ´ì§€ ì‹œê°„ (ms) */
  sentenceEndPause: number;
  /** ì§ˆë¬¸ í›„ íœ´ì§€ ì‹œê°„ (ms) */
  questionPause: number;
  /** ê°íƒ„ í›„ íœ´ì§€ ì‹œê°„ (ms) */
  exclamationPause: number;
}

export interface OutputFormatConfig {
  /** ê°œë³„ ìŒì„± íŒŒì¼ ìƒì„± ì—¬ë¶€ */
  generateIndividualFiles: boolean;
  /** í†µí•© ìŒì„± íŒŒì¼ ìƒì„± ì—¬ë¶€ */
  generateMergedFile: boolean;
  /** íŒŒì¼ ëª…ëª… ê·œì¹™ */
  fileNaming: 'timestamp' | 'sequential' | 'custom';
  /** ì»¤ìŠ¤í…€ ì ‘ë‘ì‚¬ */
  customPrefix?: string;
}

export interface GeneratedVoiceFiles {
  /** ê°œë³„ ìŒì„± íŒŒì¼ë“¤ */
  individualFiles: VoiceFile[];
  /** í†µí•© ìŒì„± íŒŒì¼ */
  mergedFile?: VoiceFile;
  /** ìƒì„± ë©”íƒ€ë°ì´í„° */
  metadata: VoiceGenerationMetadata;
}

export interface VoiceFile {
  /** íŒŒì¼ ì‹ë³„ì */
  id: string;
  /** í™”ì ID */
  speakerId: 'host' | 'curator' | 'merged';
  /** íŒŒì¼ëª… */
  filename: string;
  /** ì˜¤ë””ì˜¤ ë²„í¼ */
  audioBuffer: Buffer;
  /** ì¬ìƒ ì‹œê°„ (ì´ˆ) */
  duration: number;
  /** íŒŒì¼ í¬ê¸° (ë°”ì´íŠ¸) */
  fileSize: number;
  /** MIME íƒ€ì… */
  mimeType: string;
}

export interface VoiceGenerationMetadata {
  /** ìƒì„± ì‹œê° */
  generatedAt: string;
  /** ì´ ìƒì„± ì‹œê°„ (ms) */
  totalGenerationTime: number;
  /** í™”ìë³„ í†µê³„ */
  speakerStats: SpeakerStats[];
  /** í’ˆì§ˆ ì ìˆ˜ */
  qualityScore: number;
  /** ì‚¬ìš©ëœ ì„¤ì • */
  usedConfig: MultiVoiceTTSConfig;
}

export interface SpeakerStats {
  /** í™”ì ID */
  speakerId: 'host' | 'curator';
  /** ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ */
  segmentCount: number;
  /** ì´ ë¬¸ì ìˆ˜ */
  totalChars: number;
  /** ì´ ì¬ìƒ ì‹œê°„ (ì´ˆ) */
  totalDuration: number;
  /** í‰ê·  WPM */
  averageWPM: number;
}

/**
 * ë‹¤ì¤‘ í™”ì TTS ìƒì„±ê¸°
 */
export class MultiVoiceTTSGenerator {
  
  private static readonly DEFAULT_VOICE_CONFIG: MultiVoiceTTSConfig = {
    voiceMapping: {
      host: {
        voiceName: 'ko-KR-Neural2-C',  // ë‚¨ì„± ì§„í–‰ì
        languageCode: 'ko-KR',
        ssmlGender: 'MALE',
        speakingRate: 1.15,
        pitch: 1.0,
        volumeGainDb: 0.0,
        effects: [{ type: 'large_home_entertainment' }]
      },
      curator: {
        voiceName: 'ko-KR-Neural2-A',  // ì—¬ì„± íë ˆì´í„°
        languageCode: 'ko-KR',
        ssmlGender: 'FEMALE',
        speakingRate: 1.15,
        pitch: 2.0,  // ì—¬ì„± ìŒì„±ì— ë§ê²Œ ì¡°ì •
        volumeGainDb: 0.0,
        effects: [{ type: 'large_home_entertainment' }]
      },
      differentiationLevel: 'moderate'
    },
    audioQuality: {
      encoding: 'MP3',
      sampleRateHertz: 24000,
      bitrate: 128000
    },
    conversationFlow: {
      speakerTransitionDelay: 800,
      sentenceEndPause: 500,
      questionPause: 1000,
      exclamationPause: 600
    },
    outputFormat: {
      generateIndividualFiles: true,
      generateMergedFile: true,
      fileNaming: 'timestamp'
    }
  };

  /**
   * í™”ìë³„ ìŒì„± íŒŒì¼ ìƒì„±
   */
  static async generateMultiVoiceAudio(
    speakers: SpeakerSegment[],
    config?: Partial<MultiVoiceTTSConfig>
  ): Promise<GeneratedVoiceFiles> {
    
    const startTime = Date.now();
    const finalConfig = this.mergeConfig(config);
    
    console.log('ğŸ­ ë‹¤ì¤‘ í™”ì TTS ìƒì„± ì‹œì‘:', {
      speakerCount: speakers.length,
      hostSegments: speakers.filter(s => s.speakerId === 'host').length,
      curatorSegments: speakers.filter(s => s.speakerId === 'curator').length
    });

    const individualFiles: VoiceFile[] = [];
    const speakerStats: SpeakerStats[] = [];

    // í™”ìë³„ í†µê³„ ì´ˆê¸°í™”
    const hostStats = this.initSpeakerStats('host');
    const curatorStats = this.initSpeakerStats('curator');

    // ê°œë³„ ìŒì„± íŒŒì¼ ìƒì„±
    if (finalConfig.outputFormat.generateIndividualFiles) {
      for (let i = 0; i < speakers.length; i++) {
        const segment = speakers[i];
        
        console.log(`ğŸµ ì„¸ê·¸ë¨¼íŠ¸ ${i + 1}/${speakers.length} ìƒì„± ì¤‘: ${segment.speakerId}`);
        
        const voiceFile = await this.generateSegmentAudio(segment, finalConfig, i);
        individualFiles.push(voiceFile);
        
        // í†µê³„ ì—…ë°ì´íŠ¸
        this.updateSpeakerStats(
          segment.speakerId === 'host' ? hostStats : curatorStats,
          segment
        );
      }
    }

    speakerStats.push(hostStats, curatorStats);

    // í†µí•© ìŒì„± íŒŒì¼ ìƒì„±
    let mergedFile: VoiceFile | undefined;
    if (finalConfig.outputFormat.generateMergedFile && individualFiles.length > 0) {
      console.log('ğŸ”€ í†µí•© ìŒì„± íŒŒì¼ ìƒì„± ì¤‘...');
      mergedFile = await this.mergeAudioFiles(individualFiles, speakers, finalConfig);
    }

    const totalGenerationTime = Date.now() - startTime;
    
    const metadata: VoiceGenerationMetadata = {
      generatedAt: new Date().toISOString(),
      totalGenerationTime,
      speakerStats,
      qualityScore: this.calculateQualityScore(speakerStats),
      usedConfig: finalConfig
    };

    console.log('âœ… ë‹¤ì¤‘ í™”ì TTS ìƒì„± ì™„ë£Œ:', {
      individualFiles: individualFiles.length,
      mergedFile: !!mergedFile,
      totalTime: `${totalGenerationTime}ms`,
      qualityScore: metadata.qualityScore
    });

    return {
      individualFiles,
      mergedFile,
      metadata
    };
  }

  /**
   * ê°œë³„ ì„¸ê·¸ë¨¼íŠ¸ ìŒì„± ìƒì„±
   */
  private static async generateSegmentAudio(
    segment: SpeakerSegment,
    config: MultiVoiceTTSConfig,
    index: number
  ): Promise<VoiceFile> {
    
    const voiceConfig = segment.speakerId === 'host' 
      ? config.voiceMapping.host 
      : config.voiceMapping.curator;

    // SSML ìƒì„±
    const ssml = this.generateSegmentSSML(segment, voiceConfig, config.conversationFlow);
    
    // Google Cloud TTS í˜¸ì¶œ
    const audioBuffer = await this.callGoogleTTS(ssml, voiceConfig, config.audioQuality);
    
    // íŒŒì¼ëª… ìƒì„±
    const filename = this.generateFilename(segment.speakerId, index, config.outputFormat);
    
    // ì˜¤ë””ì˜¤ ë¶„ì„
    const duration = this.estimateAudioDuration(segment.content, voiceConfig.speakingRate);
    
    return {
      id: `${segment.speakerId}_${index}`,
      speakerId: segment.speakerId,
      filename,
      audioBuffer,
      duration,
      fileSize: audioBuffer.length,
      mimeType: this.getMimeType(config.audioQuality.encoding)
    };
  }

  /**
   * SSML ìƒì„± (ì„¸ê·¸ë¨¼íŠ¸ë³„)
   */
  private static generateSegmentSSML(
    segment: SpeakerSegment,
    voiceConfig: VoiceConfig,
    flowConfig: ConversationFlowConfig
  ): string {
    
    let content = segment.content;
    
    // ì§ˆë¬¸ì— ìì—°ìŠ¤ëŸ¬ìš´ íœ´ì§€ ì¶”ê°€
    content = content.replace(/\?/g, `?<break time="${flowConfig.questionPause}ms"/>`);
    
    // ê°íƒ„ì‚¬ì— íœ´ì§€ ì¶”ê°€
    content = content.replace(/!/g, `!<break time="${flowConfig.exclamationPause}ms"/>`);
    
    // ë¬¸ì¥ ëì— ìì—°ìŠ¤ëŸ¬ìš´ íœ´ì§€ ì¶”ê°€
    content = content.replace(/\./g, `.<break time="${flowConfig.sentenceEndPause}ms"/>`);
    
    // ì¤‘ìš”í•œ ì •ë³´ ê°•ì¡°
    content = content.replace(
      /(\d+(?:,\d{3})*(?:\.\d+)?)\s*(cm|kg|ë…„|ì„¸ê¸°|ì¸µ|ëª…|ê°œ|í˜¸)/g,
      '<emphasis level="moderate">$1$2</emphasis>'
    );
    
    return `
      <speak>
        <voice name="${voiceConfig.voiceName}">
          <prosody 
            rate="${voiceConfig.speakingRate}" 
            pitch="${voiceConfig.pitch > 0 ? '+' : ''}${voiceConfig.pitch}st"
            volume="${voiceConfig.volumeGainDb > 0 ? '+' : ''}${voiceConfig.volumeGainDb}dB">
            ${content}
          </prosody>
        </voice>
      </speak>
    `.trim();
  }

  /**
   * Google Cloud TTS í˜¸ì¶œ
   */
  private static async callGoogleTTS(
    ssml: string,
    voiceConfig: VoiceConfig,
    audioConfig: AudioQualityConfig
  ): Promise<Buffer> {
    
    // NotebookLM ì „ìš© ë‹¤ì¤‘ ìŒì„± TTS API í˜¸ì¶œ
    const response = await fetch(`${process.env.NEXTAUTH_URL}/api/tts/multi-voice`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        text: ssml,
        language: voiceConfig.languageCode,
        voice: voiceConfig.voiceName,  // ì¤‘ìš”: íŠ¹ì • ìŒì„± ì§€ì •
        ssmlGender: voiceConfig.ssmlGender,
        speakingRate: voiceConfig.speakingRate,
        pitch: voiceConfig.pitch,
        volumeGainDb: voiceConfig.volumeGainDb,
        quality: 'high'
      })
    });

    if (!response.ok) {
      throw new Error(`TTS API í˜¸ì¶œ ì‹¤íŒ¨: ${response.statusText}`);
    }

    const audioData = await response.arrayBuffer();
    return Buffer.from(audioData);
  }

  /**
   * ìŒì„± íŒŒì¼ ë³‘í•©
   */
  private static async mergeAudioFiles(
    individualFiles: VoiceFile[],
    speakers: SpeakerSegment[],
    config: MultiVoiceTTSConfig
  ): Promise<VoiceFile> {
    
    console.log('âš ï¸ MP3 ë³‘í•© ë¬¸ì œë¡œ ì¸í•´ ì„ì‹œë¡œ ì²« ë²ˆì§¸ íŒŒì¼ë§Œ ì‚¬ìš©');
    console.log('ğŸ“Š ê°œë³„ íŒŒì¼ ì •ë³´:', individualFiles.map(f => ({
      id: f.id,
      speakerId: f.speakerId,
      duration: f.duration,
      size: f.fileSize
    })));
    
    // ì„ì‹œ í•´ê²°: ì²« ë²ˆì§¸ íŒŒì¼ì„ ì‚¬ìš© (ì‹¤ì œë¡œëŠ” FFmpeg í•„ìš”)
    if (individualFiles.length === 0) {
      throw new Error('ë³‘í•©í•  ê°œë³„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.');
    }
    
    // ê°€ì¥ ê¸´ íŒŒì¼ ì„ íƒ
    const longestFile = individualFiles.reduce((longest, current) => 
      current.duration > longest.duration ? current : longest
    );
    
    console.log('ğŸµ ì„ íƒëœ íŒŒì¼:', {
      speakerId: longestFile.speakerId,
      duration: longestFile.duration,
      size: longestFile.fileSize
    });
    
    const filename = this.generateMergedFilename(config.outputFormat);
    
    return {
      id: 'merged',
      speakerId: 'merged',
      filename,
      audioBuffer: longestFile.audioBuffer, // ì‹¤ì œ ì¬ìƒ ê°€ëŠ¥í•œ íŒŒì¼
      duration: longestFile.duration, // ì‹¤ì œ duration
      fileSize: longestFile.audioBuffer.length,
      mimeType: this.getMimeType(config.audioQuality.encoding)
    };
  }

  /**
   * ì„¤ì • ë³‘í•©
   */
  private static mergeConfig(config?: Partial<MultiVoiceTTSConfig>): MultiVoiceTTSConfig {
    if (!config) return this.DEFAULT_VOICE_CONFIG;
    
    return {
      ...this.DEFAULT_VOICE_CONFIG,
      ...config,
      voiceMapping: {
        ...this.DEFAULT_VOICE_CONFIG.voiceMapping,
        ...config.voiceMapping
      },
      audioQuality: {
        ...this.DEFAULT_VOICE_CONFIG.audioQuality,
        ...config.audioQuality
      },
      conversationFlow: {
        ...this.DEFAULT_VOICE_CONFIG.conversationFlow,
        ...config.conversationFlow
      },
      outputFormat: {
        ...this.DEFAULT_VOICE_CONFIG.outputFormat,
        ...config.outputFormat
      }
    };
  }

  /**
   * íŒŒì¼ëª… ìƒì„±
   */
  private static generateFilename(
    speakerId: 'host' | 'curator',
    index: number,
    format: OutputFormatConfig
  ): string {
    
    const speakerName = speakerId === 'host' ? 'host' : 'curator';
    const timestamp = Date.now();
    
    switch (format.fileNaming) {
      case 'timestamp':
        return `${speakerName}_${timestamp}_${index}.mp3`;
      case 'sequential':
        return `${speakerName}_${String(index + 1).padStart(3, '0')}.mp3`;
      case 'custom':
        return `${format.customPrefix || 'audio'}_${speakerName}_${index}.mp3`;
      default:
        return `${speakerName}_${index}.mp3`;
    }
  }

  /**
   * í†µí•© íŒŒì¼ëª… ìƒì„±
   */
  private static generateMergedFilename(format: OutputFormatConfig): string {
    const timestamp = Date.now();
    
    switch (format.fileNaming) {
      case 'timestamp':
        return `podcast_merged_${timestamp}.mp3`;
      case 'sequential':
        return `podcast_merged_001.mp3`;
      case 'custom':
        return `${format.customPrefix || 'podcast'}_merged.mp3`;
      default:
        return `podcast_merged.mp3`;
    }
  }

  /**
   * MIME íƒ€ì… ë°˜í™˜
   */
  private static getMimeType(encoding: string): string {
    const mimeTypes: { [key: string]: string } = {
      'MP3': 'audio/mpeg',
      'LINEAR16': 'audio/wav',
      'OGG_OPUS': 'audio/ogg'
    };
    return mimeTypes[encoding] || 'audio/mpeg';
  }

  /**
   * ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œê°„ ì¶”ì •
   */
  private static estimateAudioDuration(content: string, speakingRate: number): number {
    // í•œêµ­ì–´ ê¸°ì¤€: ë¶„ë‹¹ 200ì, ì†ë„ ì¡°ì ˆ ì ìš©
    const baseCharsPerMinute = 200;
    const adjustedCharsPerMinute = baseCharsPerMinute * speakingRate;
    return Math.ceil((content.length / adjustedCharsPerMinute) * 60);
  }

  /**
   * í™”ì í†µê³„ ì´ˆê¸°í™”
   */
  private static initSpeakerStats(speakerId: 'host' | 'curator'): SpeakerStats {
    return {
      speakerId,
      segmentCount: 0,
      totalChars: 0,
      totalDuration: 0,
      averageWPM: 0
    };
  }

  /**
   * í™”ì í†µê³„ ì—…ë°ì´íŠ¸
   */
  private static updateSpeakerStats(stats: SpeakerStats, segment: SpeakerSegment): void {
    stats.segmentCount++;
    stats.totalChars += segment.content.length;
    stats.totalDuration += segment.estimatedDuration || 0;
    stats.averageWPM = Math.round((stats.totalChars / 5) / (stats.totalDuration / 60));
  }

  /**
   * í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
   */
  private static calculateQualityScore(speakerStats: SpeakerStats[]): number {
    let score = 100;
    
    const totalSegments = speakerStats.reduce((sum, stat) => sum + stat.segmentCount, 0);
    const hostSegments = speakerStats.find(s => s.speakerId === 'host')?.segmentCount || 0;
    const curatorSegments = speakerStats.find(s => s.speakerId === 'curator')?.segmentCount || 0;
    
    // í™”ì ê· í˜• ì ìˆ˜ (ì´ìƒì : 50:50)
    const balance = Math.abs(hostSegments - curatorSegments) / totalSegments;
    score -= balance * 20;
    
    // ì´ ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜ ì ìˆ˜ (ë„ˆë¬´ ì ìœ¼ë©´ ê°ì )
    if (totalSegments < 4) score -= 15;
    
    // ê° í™”ìì˜ ìµœì†Œ ê¸°ì—¬ë„ ì²´í¬
    if (hostSegments === 0 || curatorSegments === 0) score -= 30;
    
    return Math.max(0, Math.min(100, score));
  }
}

/**
 * í¸ì˜ í•¨ìˆ˜ë“¤
 */
export async function generateMultiVoicePodcast(
  speakers: SpeakerSegment[],
  config?: Partial<MultiVoiceTTSConfig>
): Promise<GeneratedVoiceFiles> {
  return MultiVoiceTTSGenerator.generateMultiVoiceAudio(speakers, config);
}

export function createVoiceConfig(
  speakerId: 'host' | 'curator',
  customization?: Partial<VoiceConfig>
): VoiceConfig {
  const base = speakerId === 'host' 
    ? MultiVoiceTTSGenerator['DEFAULT_VOICE_CONFIG'].voiceMapping.host
    : MultiVoiceTTSGenerator['DEFAULT_VOICE_CONFIG'].voiceMapping.curator;
    
  return { ...base, ...customization };
}

export default MultiVoiceTTSGenerator;