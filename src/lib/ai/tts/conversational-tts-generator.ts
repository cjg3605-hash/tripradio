// ëŒ€í™”í˜• TTS ìƒì„±ê¸° - NotebookLM ìŠ¤íƒ€ì¼ êµ¬í˜„
// ì´ì¤‘ ìŠ¤í¬ë¦½íŠ¸ + ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ + Google Cloud TTS í†µí•©

import { TTSExpertPersona, TTSExpertPersonaSelector, TTSScriptOptimizer } from '../personas/tts-expert-persona';
import { DualScriptGenerator, UserChapterScript, TTSAudioScript } from '../scripts/dual-script-generator';

export interface ConversationalTTSConfig {
  location: string;
  language: string;
  culturalContext: string[];
  audienceLevel: 'beginner' | 'intermediate' | 'advanced';
  priority: 'engagement' | 'accuracy' | 'emotion';
  audioSettings: AudioGenerationSettings;
}

export interface AudioGenerationSettings {
  engine: 'google-cloud-tts' | 'azure-tts' | 'aws-polly';
  outputFormat: 'mp3' | 'wav' | 'ogg';
  quality: 'standard' | 'high' | 'premium';
  bitrate: string;
  enableProsodyOptimization: boolean;
  enableEmotionModulation: boolean;
}

export interface TTSGenerationResult {
  userScript: UserChapterScript;
  ttsScript: TTSAudioScript;
  audioFiles: GeneratedAudioFile[];
  metadata: TTSGenerationMetadata;
  qualityScore: number;
}

export interface GeneratedAudioFile {
  chapterIndex: number;
  speakerRole: 'primary' | 'secondary';
  audioUrl: string;
  duration: number;
  fileSize: number;
  voiceProfile: string;
}

export interface TTSGenerationMetadata {
  persona: TTSExpertPersona;
  generationTimestamp: string;
  processingTime: number;
  ssmlTagsUsed: string[];
  naturalBreakCount: number;
  emphasisCount: number;
  estimatedListeningTime: number;
}

// ğŸ™ï¸ ëŒ€í™”í˜• TTS ìƒì„±ê¸° ë©”ì¸ í´ë˜ìŠ¤
export class ConversationalTTSGenerator {
  private config: ConversationalTTSConfig;
  private persona: TTSExpertPersona;
  private dualScriptGenerator: DualScriptGenerator;

  constructor(config: ConversationalTTSConfig) {
    this.config = config;
    
    // ìµœì  í˜ë¥´ì†Œë‚˜ ì„ íƒ
    this.persona = TTSExpertPersonaSelector.selectOptimalPersona(
      this.detectContentType(config.location),
      config.audienceLevel,
      config.priority
    );

    // ì¥ì†Œë³„ í˜ë¥´ì†Œë‚˜ ë§ì¶¤í™”
    this.persona = TTSExpertPersonaSelector.customizeForLocation(
      this.persona,
      config.location,
      config.culturalContext
    );

    this.dualScriptGenerator = new DualScriptGenerator();
  }

  // ğŸš€ ë©”ì¸ TTS ìƒì„± í”„ë¡œì„¸ìŠ¤
  async generateConversationalTTS(
    rawContent: string,
    chapterTitle: string,
    chapterIndex: number
  ): Promise<TTSGenerationResult> {
    
    const startTime = Date.now();
    
    try {
      // 1ë‹¨ê³„: ì´ì¤‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
      console.log('ğŸ¯ 1ë‹¨ê³„: ì´ì¤‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘...');
      const scripts = await this.generateDualScripts(rawContent, chapterTitle, chapterIndex);
      
      // 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ í˜ë¥´ì†Œë‚˜ ìµœì í™”
      console.log('ğŸ­ 2ë‹¨ê³„: TTS ìŠ¤í¬ë¦½íŠ¸ í˜ë¥´ì†Œë‚˜ ìµœì í™” ì¤‘...');
      const optimizedTTSScript = this.optimizeTTSScript(scripts.ttsScript);
      
      // 3ë‹¨ê³„: ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±
      console.log('ğŸ”Š 3ë‹¨ê³„: ëŒ€í™”í˜• ì˜¤ë””ì˜¤ ìƒì„± ì¤‘...');
      const audioFiles = await this.generateConversationalAudio(optimizedTTSScript);
      
      // 4ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦
      console.log('âœ… 4ë‹¨ê³„: í’ˆì§ˆ ê²€ì¦ ì¤‘...');
      const qualityScore = this.evaluateQuality(optimizedTTSScript, audioFiles);
      
      // 5ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ìƒì„±
      const metadata = this.generateMetadata(optimizedTTSScript, startTime);
      
      return {
        userScript: scripts.userScript,
        ttsScript: optimizedTTSScript,
        audioFiles,
        metadata,
        qualityScore
      };
      
    } catch (error) {
      console.error('âŒ TTS ìƒì„± ì‹¤íŒ¨:', error);
      throw new Error(`TTS ìƒì„± ì‹¤íŒ¨: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  // ğŸ“ ì´ì¤‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
  private async generateDualScripts(
    rawContent: string,
    chapterTitle: string, 
    chapterIndex: number
  ): Promise<{ userScript: UserChapterScript; ttsScript: TTSAudioScript }> {
    
    const scripts = await this.dualScriptGenerator.generateDualScripts(
      rawContent,
      chapterTitle,
      chapterIndex,
      this.config.location,
      this.config.language
    );
    
    return scripts;
  }

  // ğŸ­ TTS ìŠ¤í¬ë¦½íŠ¸ í˜ë¥´ì†Œë‚˜ ìµœì í™”
  private optimizeTTSScript(ttsScript: TTSAudioScript): TTSAudioScript {
    
    // ì§„í–‰ì ìŠ¤í¬ë¦½íŠ¸ ìµœì í™”
    const optimizedHostScript = TTSScriptOptimizer.optimizeForPersona(
      ttsScript.hostScript || '',
      this.persona,
      'primary'
    );
    
    // íë ˆì´í„° ìŠ¤í¬ë¦½íŠ¸ ìµœì í™”
    const optimizedCuratorScript = TTSScriptOptimizer.optimizeForPersona(
      ttsScript.curatorScript || '',
      this.persona,
      'secondary'
    );
    
    // í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìµœì í™”
    const optimizedCombinedScript = this.optimizeCombinedScript(ttsScript.combinedScript || '');
    
    return {
      ...ttsScript,
      hostScript: optimizedHostScript,
      curatorScript: optimizedCuratorScript,
      combinedScript: optimizedCombinedScript,
      systemPrompt: TTSScriptOptimizer.generateSystemPrompt(this.persona, this.config.location)
    };
  }

  // ğŸµ í†µí•© ìŠ¤í¬ë¦½íŠ¸ ìµœì í™” (NotebookLM ìŠ¤íƒ€ì¼)
  private optimizeCombinedScript(combinedScript: string): string {
    let optimized = combinedScript;
    
    // 1. NotebookLM ìŠ¤íƒ€ì¼ ëŒ€í™” íë¦„ ìµœì í™”
    optimized = this.applyNotebookLMConversationFlow(optimized);
    
    // 2. ìì—°ìŠ¤ëŸ¬ìš´ í™”ì ì „í™˜ ìµœì í™”
    optimized = this.optimizeSpeakerTransitions(optimized);
    
    // 3. ê°ì • ë‹¤ì´ë‚´ë¯¹ìŠ¤ ì ìš©
    optimized = this.applyEmotionalDynamics(optimized);
    
    // 4. ë°œìŒ ìµœì í™” (ì™¸êµ­ì–´, ì „ë¬¸ìš©ì–´)
    optimized = this.optimizePronunciation(optimized);
    
    return optimized;
  }

  // ğŸ—£ï¸ NotebookLM ìŠ¤íƒ€ì¼ ëŒ€í™” íë¦„ ì ìš©
  private applyNotebookLMConversationFlow(script: string): string {
    let optimized = script;
    
    // NotebookLMì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¼ì–´ë“¤ê¸° íŒ¨í„´
    const interruptionPatterns = [
      'ê·¸ëŸ°ë° ë§ì´ì•¼',
      'ì•„, ê·¸ê±° ì •ë§ í¥ë¯¸ë¡œìš´ ì ì´ì•¼',
      'ì ê¹, ì´ê²ƒë„ ì¬ë°ŒëŠ”ë°',
      'ê·¸ë˜ì„œ ë‚´ê°€ ë§í•˜ê³  ì‹¶ì€ ê±´'
    ];
    
    // ì •ë³´ ë ˆì´ì–´ë§ ì ìš© (ê¸°ë³¸ â†’ í¥ë¯¸ë¡œìš´ â†’ ë†€ë¼ìš´)
    const layeringCues = [
      { trigger: 'ê¸°ë³¸ì ìœ¼ë¡œ', replacement: '<prosody rate="1.0">ê¸°ë³¸ì ìœ¼ë¡œ' },
      { trigger: 'í¥ë¯¸ë¡­ê²Œë„', replacement: '<prosody rate="1.1" pitch="+1st">í¥ë¯¸ë¡­ê²Œë„' },
      { trigger: 'ë†€ëê²Œë„', replacement: '<prosody rate="0.9" pitch="+2st" volume="loud">ë†€ëê²Œë„' }
    ];
    
    layeringCues.forEach(cue => {
      const regex = new RegExp(cue.trigger, 'gi');
      optimized = optimized.replace(regex, `${cue.replacement}</prosody>`);
    });
    
    // ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ê³¼ ê°íƒ„ì‚¬ ì¶”ê°€
    const reactionPatterns = [
      { after: 'ì •ë§', add: '<break time="0.3s"/> ê·¸ëŸ¬ê²Œ ë§ì´ì•¼ <break time="0.5s"/>' },
      { after: 'ëŒ€ë‹¨í•œ', add: '<break time="0.4s"/> ì •ë§ ë†€ë¼ì›Œ <break time="0.6s"/>' }
    ];
    
    return optimized;
  }

  // ğŸ”„ ìì—°ìŠ¤ëŸ¬ìš´ í™”ì ì „í™˜ ìµœì í™”
  private optimizeSpeakerTransitions(script: string): string {
    let optimized = script;
    
    // í™”ì ì „í™˜ ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ íœ´ì§€ì™€ ì „í™˜ íš¨ê³¼
    optimized = optimized.replace(
      /\*\*ì§„í–‰ì:\*\*/g,
      '<break time="0.8s"/><prosody rate="1.05" pitch="+1st">**ì§„í–‰ì:**</prosody>'
    );
    
    optimized = optimized.replace(
      /\*\*íë ˆì´í„°:\*\*/g,
      '<break time="0.8s"/><prosody rate="0.95" pitch="-1st">**íë ˆì´í„°:**</prosody>'
    );
    
    // ëŒ€í™”ì˜ ì—°ê²°ì„±ì„ ë†’ì´ëŠ” ì „í™˜ êµ¬ë¬¸ ì¶”ê°€
    const transitionPhrases = this.persona.voiceProfile.conversationFlow.transitionCues;
    
    return optimized;
  }

  // ğŸ’« ê°ì • ë‹¤ì´ë‚´ë¯¹ìŠ¤ ì ìš©
  private applyEmotionalDynamics(script: string): string {
    let optimized = script;
    
    // ê°ì •ì  í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì‹ë³„ ë° ìµœì í™”
    const emotionalKeywords = {
      wonder: ['ë†€ë¼ìš´', 'ê²½ì´ë¡œìš´', 'ì‹ ë¹„ë¡œìš´', 'ì•„ë¦„ë‹¤ìš´'],
      excitement: ['í¥ë¯¸ì§„ì§„í•œ', 'ì¬ë°ŒëŠ”', 'ë†€ë¼ìš´', 'ëŒ€ë‹¨í•œ'],
      reverence: ['ê²½ê±´í•œ', 'ìˆ­ê³ í•œ', 'ì˜ë¯¸ ìˆëŠ”', 'ê¹Šì€'],
      curiosity: ['ê¶ê¸ˆí•œ', 'í¥ë¯¸ë¡œìš´', 'ì‹ ê¸°í•œ', 'ì´ìƒí•œ']
    };
    
    // ê°ì •ë³„ SSML ìµœì í™” ì ìš©
    Object.entries(emotionalKeywords).forEach(([emotion, keywords]) => {
      keywords.forEach(keyword => {
        const emotionSSML = this.getEmotionSSML(emotion);
        const regex = new RegExp(`\\b${keyword}\\b`, 'gi');
        optimized = optimized.replace(regex, `${emotionSSML}${keyword}</prosody>`);
      });
    });
    
    return optimized;
  }

  // ğŸµ ê°ì •ë³„ SSML íƒœê·¸ ìƒì„±
  private getEmotionSSML(emotion: string): string {
    const emotionMap: { [key: string]: string } = {
      wonder: '<prosody rate="0.9" pitch="+2st" volume="medium">',
      excitement: '<prosody rate="1.2" pitch="+1st" volume="loud">',
      reverence: '<prosody rate="0.8" pitch="-1st" volume="soft">',
      curiosity: '<prosody rate="1.1" pitch="+1st" volume="medium">'
    };
    
    return emotionMap[emotion] || '<prosody>';
  }

  // ğŸ—£ï¸ ë°œìŒ ìµœì í™” (ì™¸êµ­ì–´, ì „ë¬¸ìš©ì–´)
  private optimizePronunciation(script: string): string {
    let optimized = script;
    
    // ì™¸êµ­ì–´ ë°œìŒ ê°€ì´ë“œ ë§µ
    const pronunciationMap: { [key: string]: string } = {
      'Louvre': '<phoneme alphabet="ipa" ph="luËvrÉ™">ë£¨ë¸Œë¥´</phoneme>',
      'Notre-Dame': '<phoneme alphabet="ipa" ph="nÉ”trÉ™ dam">ë…¸íŠ¸ë¥´ë‹´</phoneme>',
      'Versailles': '<phoneme alphabet="ipa" ph="vÉ›ÊsaÉª">ë² ë¥´ì‚¬ìœ </phoneme>',
      'Renaissance': '<phoneme alphabet="ipa" ph="rÉ™nÉ›sÉ‘Ìƒs">ë¥´ë„¤ìƒìŠ¤</phoneme>',
      'Baroque': '<phoneme alphabet="ipa" ph="bÉ™ËˆroÊŠk">ë°”ë¡œí¬</phoneme>'
    };
    
    // ë°œìŒ ê°€ì´ë“œ ì ìš©
    Object.entries(pronunciationMap).forEach(([original, phoneme]) => {
      const regex = new RegExp(original, 'gi');
      optimized = optimized.replace(regex, phoneme);
    });
    
    return optimized;
  }

  // ğŸ”Š ëŒ€í™”í˜• ì˜¤ë””ì˜¤ ìƒì„±
  private async generateConversationalAudio(
    ttsScript: TTSAudioScript
  ): Promise<GeneratedAudioFile[]> {
    
    const audioFiles: GeneratedAudioFile[] = [];
    
    try {
      // Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
      const ttsClient = await this.initializeTTSClient();
      
      // ì§„í–‰ì ìŒì„± ìƒì„±
      const hostAudio = await this.generateSpeakerAudio(
        ttsScript.hostScript || '',
        this.persona.voiceProfile.primarySpeaker,
        'primary',
        ttsClient
      );
      
      if (hostAudio) audioFiles.push(hostAudio);
      
      // íë ˆì´í„° ìŒì„± ìƒì„±  
      const curatorAudio = await this.generateSpeakerAudio(
        ttsScript.curatorScript || '',
        this.persona.voiceProfile.secondarySpeaker,
        'secondary',
        ttsClient
      );
      
      if (curatorAudio) audioFiles.push(curatorAudio);
      
      // í†µí•© ëŒ€í™” ìŒì„± ìƒì„± (ë©”ì¸ íŒŒì¼)
      const combinedAudio = await this.generateCombinedConversation(
        ttsScript.combinedScript || '',
        ttsClient
      );
      
      if (combinedAudio) audioFiles.push(combinedAudio);
      
      return audioFiles;
      
    } catch (error) {
      console.error('âŒ ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // ğŸ¤ ê°œë³„ í™”ì ìŒì„± ìƒì„±
  private async generateSpeakerAudio(
    script: string,
    voiceConfig: any,
    role: 'primary' | 'secondary',
    ttsClient: any
  ): Promise<GeneratedAudioFile | null> {
    
    if (!script || script.trim().length === 0) {
      return null;
    }
    
    try {
      const request = {
        input: { ssml: script },
        voice: {
          languageCode: this.config.language,
          name: voiceConfig.voiceId,
          ssmlGender: role === 'primary' ? 'FEMALE' : 'MALE'
        },
        audioConfig: {
          audioEncoding: this.getAudioEncoding(),
          pitch: this.parsePitch(voiceConfig.pitch),
          speakingRate: parseFloat(voiceConfig.rate),
          volumeGainDb: this.parseVolume(voiceConfig.volume)
        }
      };
      
      const [response] = await ttsClient.synthesizeSpeech(request);
      
      // ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë° URL ìƒì„±
      const audioUrl = await this.saveAudioFile(response.audioContent, role);
      const duration = this.estimateAudioDuration(script);
      
      return {
        chapterIndex: 0, // ì‹¤ì œ ì±•í„° ì¸ë±ìŠ¤ë¡œ ëŒ€ì²´ í•„ìš”
        speakerRole: role,
        audioUrl,
        duration,
        fileSize: response.audioContent.length,
        voiceProfile: voiceConfig.voiceId
      };
      
    } catch (error) {
      console.error(`âŒ ${role} í™”ì ìŒì„± ìƒì„± ì‹¤íŒ¨:`, error);
      return null;
    }
  }

  // ğŸ­ í†µí•© ëŒ€í™” ìŒì„± ìƒì„± (NotebookLM ìŠ¤íƒ€ì¼)
  private async generateCombinedConversation(
    combinedScript: string,
    ttsClient: any
  ): Promise<GeneratedAudioFile | null> {
    
    try {
      // NotebookLM ìŠ¤íƒ€ì¼ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ„í•œ íŠ¹ë³„ ì²˜ë¦¬
      const conversationSSML = this.createConversationSSML(combinedScript);
      
      const request = {
        input: { ssml: conversationSSML },
        voice: {
          languageCode: this.config.language,
          name: this.persona.voiceProfile.primarySpeaker.voiceId
        },
        audioConfig: {
          audioEncoding: this.getAudioEncoding(),
          effectsProfileId: ['telephony-class-application'], // ëŒ€í™” í’ˆì§ˆ í–¥ìƒ
          pitch: 0,
          speakingRate: 1.0,
          volumeGainDb: 0
        }
      };
      
      const [response] = await ttsClient.synthesizeSpeech(request);
      
      const audioUrl = await this.saveAudioFile(response.audioContent, 'combined');
      const duration = this.estimateAudioDuration(combinedScript);
      
      return {
        chapterIndex: 0,
        speakerRole: 'primary',
        audioUrl,
        duration,
        fileSize: response.audioContent.length,
        voiceProfile: 'conversational'
      };
      
    } catch (error) {
      console.error('âŒ í†µí•© ëŒ€í™” ìŒì„± ìƒì„± ì‹¤íŒ¨:', error);
      return null;
    }
  }

  // ğŸµ ëŒ€í™”ìš© SSML ìƒì„± (í™”ì ì „í™˜ ìµœì í™”)
  private createConversationSSML(script: string): string {
    let ssml = `<speak>${script}</speak>`;
    
    // í™”ìë³„ ìŒì„± í”„ë¡œí•„ ì ìš©
    ssml = ssml.replace(
      /\*\*ì§„í–‰ì:\*\*(.*?)(?=\*\*íë ˆì´í„°:\*\*|$)/gs,
      (match, content) => {
        const hostVoice = this.persona.voiceProfile.primarySpeaker;
        return `<voice name="${hostVoice.voiceId}">
          <prosody rate="${hostVoice.rate}" pitch="${hostVoice.pitch}">
            **ì§„í–‰ì:**${content}
          </prosody>
        </voice>`;
      }
    );
    
    ssml = ssml.replace(
      /\*\*íë ˆì´í„°:\*\*(.*?)(?=\*\*ì§„í–‰ì:\*\*|$)/gs,
      (match, content) => {
        const curatorVoice = this.persona.voiceProfile.secondarySpeaker;
        return `<voice name="${curatorVoice.voiceId}">
          <prosody rate="${curatorVoice.rate}" pitch="${curatorVoice.pitch}">
            **íë ˆì´í„°:**${content}
          </prosody>
        </voice>`;
      }
    );
    
    return ssml;
  }

  // âš™ï¸ í—¬í¼ ë©”ì„œë“œë“¤
  private detectContentType(location: string): 'museum' | 'historical' | 'cultural' | 'technical' {
    if (location.includes('ë°•ë¬¼ê´€') || location.includes('ë¯¸ìˆ ê´€')) return 'museum';
    if (location.includes('ê¶') || location.includes('ì„±') || location.includes('ìœ ì ')) return 'historical';
    if (location.includes('ë¬¸í™”') || location.includes('ì „í†µ')) return 'cultural';
    return 'museum';
  }

  private async initializeTTSClient(): Promise<any> {
    // Google Cloud TTS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë¡œì§
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” @google-cloud/text-to-speech íŒ¨í‚¤ì§€ ì‚¬ìš©
    return {
      synthesizeSpeech: async (request: any) => {
        // TTS ìƒì„± ë¡œì§ (ì‹¤ì œ êµ¬í˜„ í•„ìš”)
        return [{ audioContent: Buffer.from('mock audio data') }];
      }
    };
  }

  private getAudioEncoding(): string {
    const formatMap: { [key: string]: string } = {
      'mp3': 'MP3',
      'wav': 'LINEAR16', 
      'ogg': 'OGG_OPUS'
    };
    return formatMap[this.config.audioSettings.outputFormat] || 'MP3';
  }

  private parsePitch(pitch: string): number {
    if (pitch === 'default') return 0;
    const match = pitch.match(/([+-]?\d+)st/);
    return match ? parseInt(match[1]) * 2 : 0; // semitones to Hz conversion
  }

  private parseVolume(volume: string): number {
    const volumeMap: { [key: string]: number } = {
      'soft': -10,
      'medium': 0,
      'loud': 6
    };
    return volumeMap[volume] || 0;
  }

  private async saveAudioFile(audioContent: Buffer, type: string): Promise<string> {
    // ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ë¡œì§ (Supabase Storage ë“±)
    const filename = `tts-${type}-${Date.now()}.${this.config.audioSettings.outputFormat}`;
    // ì‹¤ì œ ì €ì¥ ë¡œì§ êµ¬í˜„ í•„ìš”
    return `https://storage.example.com/audio/${filename}`;
  }

  private estimateAudioDuration(script: string): number {
    // ìŠ¤í¬ë¦½íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¬ìƒ ì‹œê°„ ì¶”ì • (í‰ê·  150 WPM)
    const words = script.replace(/<[^>]+>/g, '').split(' ').length;
    return Math.round((words / 150) * 60); // seconds
  }

  private evaluateQuality(ttsScript: TTSAudioScript, audioFiles: GeneratedAudioFile[]): number {
    // TTS í’ˆì§ˆ í‰ê°€ ë¡œì§
    let score = 0;
    
    // SSML íƒœê·¸ ì‚¬ìš©ë„ í‰ê°€ (30ì )
    const ssmlCount = (ttsScript.combinedScript?.match(/<[^>]+>/g) || []).length;
    score += Math.min(30, ssmlCount * 2);
    
    // ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì„±ê³µë¥  (40ì )
    const successRate = audioFiles.length / 3; // ì˜ˆìƒ 3ê°œ íŒŒì¼
    score += successRate * 40;
    
    // í˜ë¥´ì†Œë‚˜ íŠ¹ì„± ë°˜ì˜ë„ (30ì )
    const hasPersonaElements = this.persona.characteristics.some(char =>
      ttsScript.combinedScript?.toLowerCase().includes(char.slice(0, 5).toLowerCase())
    );
    score += hasPersonaElements ? 30 : 15;
    
    return Math.min(100, score);
  }

  private generateMetadata(ttsScript: TTSAudioScript, startTime: number): TTSGenerationMetadata {
    const processingTime = Date.now() - startTime;
    const ssmlTags = (ttsScript.combinedScript?.match(/<[^>]+>/g) || []).map(tag => 
      tag.replace(/[<>]/g, '').split(' ')[0]
    );
    
    return {
      persona: this.persona,
      generationTimestamp: new Date().toISOString(),
      processingTime,
      ssmlTagsUsed: [...new Set(ssmlTags)],
      naturalBreakCount: (ttsScript.combinedScript?.match(/<break/g) || []).length,
      emphasisCount: (ttsScript.combinedScript?.match(/<emphasis/g) || []).length,
      estimatedListeningTime: this.estimateAudioDuration(ttsScript.combinedScript || '')
    };
  }
}

// ğŸ­ ëŒ€í™”í˜• TTS íŒ©í† ë¦¬
export class ConversationalTTSFactory {
  
  static createGenerator(
    location: string,
    language: string = 'ko-KR',
    options: Partial<ConversationalTTSConfig> = {}
  ): ConversationalTTSGenerator {
    
    const defaultConfig: ConversationalTTSConfig = {
      location,
      language,
      culturalContext: [],
      audienceLevel: 'intermediate',
      priority: 'engagement',
      audioSettings: {
        engine: 'google-cloud-tts',
        outputFormat: 'mp3',
        quality: 'high',
        bitrate: '128kbps',
        enableProsodyOptimization: true,
        enableEmotionModulation: true
      }
    };
    
    const config = { ...defaultConfig, ...options };
    return new ConversationalTTSGenerator(config);
  }
  
  static createForMuseum(location: string): ConversationalTTSGenerator {
    return this.createGenerator(location, 'ko-KR', {
      culturalContext: ['educational', 'cultural', 'respectful'],
      priority: 'emotion',
      audienceLevel: 'intermediate'
    });
  }
  
  static createForHistoricalSite(location: string): ConversationalTTSGenerator {
    return this.createGenerator(location, 'ko-KR', {
      culturalContext: ['historical', 'reverent', 'educational'],
      priority: 'accuracy',
      audienceLevel: 'intermediate'
    });
  }
}

// ëª¨ë“  í´ë˜ìŠ¤ëŠ” ì´ë¯¸ ìœ„ì—ì„œ export ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì œê±°