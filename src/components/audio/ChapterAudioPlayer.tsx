'use client';

import React, { useState, useRef, useEffect } from 'react';
import { useLanguage } from '@/contexts/LanguageContext';
import {
  Play,
  Pause,
  Volume2,
  VolumeX,
  Mic,
  Loader2
} from 'lucide-react';
import { AudioChapter } from '@/types/audio';
// TTSëŠ” APIë¥¼ í†µí•´ ìƒì„±

interface ChapterAudioPlayerProps {
  chapter: AudioChapter;
  className?: string;
  onChapterUpdate?: (updatedChapter: AudioChapter) => void;
  locationName?: string;
  guideId?: string;
  // ğŸŒ ì–¸ì–´ë³„ ìµœì í™”ëœ TTSë¥¼ ìœ„í•œ ì–¸ì–´ ì •ë³´
  contentLanguage?: string;
}

const ChapterAudioPlayer: React.FC<ChapterAudioPlayerProps> = ({
  chapter,
  className = '',
  onChapterUpdate,
  locationName = 'guide',
  guideId = 'default',
  contentLanguage
}) => {
  const { t, currentLanguage, currentConfig } = useLanguage();
  const audioRef = useRef<HTMLAudioElement>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [volume, setVolume] = useState(1);
  const [isMuted, setIsMuted] = useState(false);
  const [isGeneratingTTS, setIsGeneratingTTS] = useState(false);
  const [ttsError, setTtsError] = useState<string | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(chapter.audioUrl || null);

  // ì‹œê°„ í¬ë§·íŒ…
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const handleTimeUpdate = () => setCurrentTime(audio.currentTime);
    const handleDurationChange = () => setDuration(audio.duration);
    const handleEnded = () => setIsPlaying(false);
    const handlePlay = () => setIsPlaying(true);
    const handlePause = () => setIsPlaying(false);

    audio.addEventListener('timeupdate', handleTimeUpdate);
    audio.addEventListener('durationchange', handleDurationChange);
    audio.addEventListener('ended', handleEnded);
    audio.addEventListener('play', handlePlay);
    audio.addEventListener('pause', handlePause);

    return () => {
      audio.removeEventListener('timeupdate', handleTimeUpdate);
      audio.removeEventListener('durationchange', handleDurationChange);
      audio.removeEventListener('ended', handleEnded);
      audio.removeEventListener('play', handlePlay);
      audio.removeEventListener('pause', handlePause);
    };
  }, []);

  // ì¬ìƒ/ì¼ì‹œì •ì§€
  const togglePlayPause = async () => {
    if (!audioRef.current) return;

    // ğŸ¯ TTS ìƒì„± ì¤‘ì´ë©´ ë¬´ì‹œ
    if (isGeneratingTTS) {
      console.log('ğŸ”„ TTS ìƒì„± ì¤‘ì´ë¯€ë¡œ ë²„íŠ¼ í´ë¦­ ë¬´ì‹œ');
      return;
    }

    // ğŸ™ï¸ ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ TLS ìƒì„± í›„ ìë™ ì¬ìƒ
    if (!audioUrl) {
      console.log('ğŸ™ï¸ ì˜¤ë””ì˜¤ ì—†ìŒ - TLS ìƒì„± ì‹œì‘');
      await generateTTS();
      return;
    }

    // â–¶ï¸ ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ ì¬ìƒ/ì¼ì‹œì •ì§€
    if (audioUrl && audioRef.current) {
      try {
        if (isPlaying) {
          console.log('â¸ï¸ ì˜¤ë””ì˜¤ ì¼ì‹œì •ì§€');
          audioRef.current.pause();
        } else {
          console.log('â–¶ï¸ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘');
          await audioRef.current.play();
        }
        // ìƒíƒœëŠ” ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆì—ì„œ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë¨
      } catch (error) {
        console.error('âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error);
        setIsPlaying(false);
        setTtsError('ì˜¤ë””ì˜¤ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      }
    }
  };

  // ì§„í–‰ë¥  í´ë¦­
  const handleProgressClick = (event: React.MouseEvent<HTMLDivElement>) => {
    if (!audioRef.current) return;
    
    const rect = event.currentTarget.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const percentage = x / rect.width;
    const newTime = percentage * duration;
    
    audioRef.current.currentTime = newTime;
    setCurrentTime(newTime);
  };

  // ìŒì†Œê±° í† ê¸€
  const toggleMute = () => {
    if (!audioRef.current) return;
    
    const newMuted = !isMuted;
    setIsMuted(newMuted);
    audioRef.current.muted = newMuted;
  };

  // ğŸŒ ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„± (Neural2 ê¸°ë°˜ ë„¤ì´í‹°ë¸Œ ìŒì„±)
  const generateTTS = async () => {
    if (!chapter.text || isGeneratingTTS) return;

    setIsGeneratingTTS(true);
    setTtsError(null);

    // ê¸°ì¡´ ì˜¤ë””ì˜¤ ìºì‹œ ì •ë¦¬
    if (audioUrl && audioUrl.startsWith('blob:')) {
      URL.revokeObjectURL(audioUrl);
      setAudioUrl(null);
    }

    try {
      // ğŸ¯ ì–¸ì–´ ìë™ ê°ì§€: ìš°ì„ ìˆœìœ„ - contentLanguage > chapter.language > context ttsLang > ko-KR
      const detectedLanguage = contentLanguage || chapter.language || currentConfig.ttsLang || 'ko-KR';
      
      console.log('ğŸŒ ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„± ì‹œì‘:', { 
        chapterId: chapter.id, 
        textLength: chapter.text.length,
        contentLanguage,
        chapterLanguage: chapter.language,
        contextLanguage: currentLanguage,
        contextTtsLang: currentConfig.ttsLang,
        detectedLanguage,
        preview: chapter.text.substring(0, 50) + '...'
      });

      // ğŸ§¬ ì–¸ì–´ë³„ ìµœì í™”ëœ TTS API í˜¸ì¶œ
      const response = await fetch('/api/tts', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: chapter.text,
          language: detectedLanguage,
          quality: 'high' // Neural2 í’ˆì§ˆ ì‚¬ìš©
        })
      });

      if (!response.ok) {
        throw new Error(`TTS API í˜¸ì¶œ ì‹¤íŒ¨: ${response.status}`);
      }

      const result = await response.json();

      if (result.success && result.audioData) {
        // Base64 ë°ì´í„°ë¥¼ data URLë¡œ ë³€í™˜
        const audioUrl = `data:${result.mimeType || 'audio/mpeg'};base64,${result.audioData}`;
        setAudioUrl(audioUrl);
        setIsGeneratingTTS(false);
        
        // ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì—…ë°ì´íŠ¸ëœ ì±•í„° ì •ë³´ ì „ë‹¬
        if (onChapterUpdate) {
          onChapterUpdate({
            ...chapter,
            audioUrl: audioUrl,
            isGeneratingTTS: false,
            ttsError: undefined
          });
        }

        console.log('âœ… ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„± ì™„ë£Œ:', { 
          chapterId: chapter.id,
          audioSize: result.audioData?.length || 0,
          mimeType: result.mimeType,
          language: result.language,
          voiceName: result.voiceName,
          quality: result.quality,
          culturalAdaptation: result.culturalAdaptation,
          requestedLanguage: detectedLanguage
        });

        // ğŸµ ìƒì„± ì™„ë£Œ í›„ ìë™ ì¬ìƒ
        setTimeout(async () => {
          if (audioRef.current && audioUrl) {
            try {
              console.log('ğŸµ ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„± ì™„ë£Œ - ìë™ ì¬ìƒ ì‹œì‘:', {
                language: result.language,
                voice: result.voiceName,
                quality: result.quality
              });
              await audioRef.current.play();
              // ìƒíƒœëŠ” play ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆì—ì„œ ìë™ ì—…ë°ì´íŠ¸ë¨
            } catch (error) {
              console.error('âŒ ìë™ ì¬ìƒ ì‹¤íŒ¨:', error);
              setTtsError('ìë™ ì¬ìƒì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¬ìƒ ë²„íŠ¼ì„ ì§ì ‘ ëˆŒëŸ¬ì£¼ì„¸ìš”.');
            }
          }
        }, 200);

        return;
      }

      // ì‹¤íŒ¨ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€
      throw new Error(result.error || 'ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');

    } catch (error) {
      console.error('âŒ ì–¸ì–´ë³„ ìµœì í™”ëœ TTS ìƒì„± ì‹¤íŒ¨:', error);
      const errorMessage = error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” TTS ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      
      // ì—ëŸ¬ ìƒíƒœ ì—…ë°ì´íŠ¸
      setTtsError(`TTS ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
      setIsGeneratingTTS(false);
      
      if (onChapterUpdate) {
        onChapterUpdate({
          ...chapter,
          isGeneratingTTS: false,
          ttsError: errorMessage
        });
      }
    } finally {
      setIsGeneratingTTS(false);
    }
  };

  // ì˜¤ë””ì˜¤ URLì´ ë³€ê²½ë˜ë©´ ì˜¤ë””ì˜¤ ìš”ì†Œ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (audioRef.current && audioUrl) {
      audioRef.current.src = audioUrl;
      audioRef.current.load();
    }
  }, [audioUrl]);

  return (
    <div className={`space-y-3 ${className}`}>
      <audio ref={audioRef} preload="metadata" />
      
      {/* í†µí•© ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ */}
      <div className="flex items-center gap-3">
        {/* ì¬ìƒ/ì¼ì‹œì •ì§€ ë²„íŠ¼ */}
        <button
          onClick={togglePlayPause}
          disabled={isGeneratingTTS}
          className={`w-8 h-8 rounded-full flex items-center justify-center transition-colors flex-shrink-0 
            ${isGeneratingTTS 
              ? 'bg-gray-400 text-white cursor-not-allowed' 
              : 'bg-black text-white hover:bg-gray-800 cursor-pointer'
            }`}
          aria-label={isGeneratingTTS ? String(t('audio.generating') || 'TTS ìƒì„± ì¤‘') : isPlaying ? String(t('audio.pause') || 'ì¼ì‹œì •ì§€') : String(t('audio.play') || 'ì¬ìƒ')}
        >
          {isGeneratingTTS ? (
            <Loader2 className="w-4 h-4 animate-spin" />
          ) : isPlaying ? (
            <Pause className="w-4 h-4" />
          ) : (
            <Play className="w-4 h-4 ml-0.5" />
          )}
        </button>

        {/* ì§„í–‰ë¥  ë°” */}
        <div className="flex-1 min-w-0">
          <div
            className="relative h-1.5 bg-gray-200 rounded-full cursor-pointer"
            onClick={handleProgressClick}
          >
            <div
              className="absolute top-0 left-0 h-full bg-black rounded-full"
              style={{ width: duration > 0 ? `${(currentTime / duration) * 100}%` : '0%' }}
            />
          </div>
          <div className="flex justify-between text-xs text-gray-500 mt-1">
            <span>{formatTime(currentTime)}</span>
            <span>{isGeneratingTTS ? 'TTS ìƒì„± ì¤‘...' : formatTime(duration)}</span>
          </div>
        </div>

        {/* ë³¼ë¥¨ */}
        <button
          onClick={toggleMute}
          disabled={!audioUrl}
          className="p-1 text-gray-600 hover:text-gray-900 transition-colors flex-shrink-0 disabled:text-gray-300"
          aria-label={isMuted ? 'ìŒì†Œê±° í•´ì œ' : 'ìŒì†Œê±°'}
        >
          {isMuted ? <VolumeX className="w-4 h-4" /> : <Volume2 className="w-4 h-4" />}
        </button>

        {/* ì¬ìƒì„± ë²„íŠ¼ (ì˜¤ë””ì˜¤ê°€ ìˆì„ ë•Œë§Œ) */}
        {audioUrl && (
          <button
            onClick={generateTTS}
            disabled={isGeneratingTTS}
            className="p-1 text-blue-600 hover:text-blue-800 transition-colors flex-shrink-0 disabled:text-gray-400"
            aria-label="TTS ì¬ìƒì„±"
            title="ìƒˆë¡œìš´ ìŒì„±ìœ¼ë¡œ ì¬ìƒì„±"
          >
            {isGeneratingTTS ? (
              <Loader2 className="w-4 h-4 animate-spin" />
            ) : (
              <Mic className="w-4 h-4" />
            )}
          </button>
        )}
      </div>
      
      {/* ì—ëŸ¬ í‘œì‹œ */}
      {ttsError && (
        <div className="text-red-600 text-sm bg-red-50 p-2 rounded">
          {ttsError}
        </div>
      )}
    </div>
  );
};

export default ChapterAudioPlayer;