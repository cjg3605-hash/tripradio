'use client';

import React, { useState, useRef, useEffect } from 'react';
import { useLanguage } from '@/contexts/LanguageContext';
import {
  Play,
  Pause,
  Volume2,
  VolumeX,
  Mic,
  Loader2
} from 'lucide-react';
import { AudioChapter } from '@/types/audio';
import { advancedTTSService } from '@/lib/advanced-tts-service';
import { neural2TTS } from '@/lib/tts/neural2-tts-service';

interface ChapterAudioPlayerProps {
  chapter: AudioChapter;
  className?: string;
  onChapterUpdate?: (updatedChapter: AudioChapter) => void;
  locationName?: string;
  guideId?: string;
}

const ChapterAudioPlayer: React.FC<ChapterAudioPlayerProps> = ({
  chapter,
  className = '',
  onChapterUpdate,
  locationName = 'guide',
  guideId = 'default'
}) => {
  const { t } = useLanguage();
  const audioRef = useRef<HTMLAudioElement>(null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [volume, setVolume] = useState(1);
  const [isMuted, setIsMuted] = useState(false);
  const [isGeneratingTTS, setIsGeneratingTTS] = useState(false);
  const [ttsError, setTtsError] = useState<string | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(chapter.audioUrl || null);

  // ì‹œê°„ í¬ë§·íŒ…
  const formatTime = (seconds: number): string => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  // ì˜¤ë””ì˜¤ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const handleTimeUpdate = () => setCurrentTime(audio.currentTime);
    const handleDurationChange = () => setDuration(audio.duration);
    const handleEnded = () => setIsPlaying(false);

    audio.addEventListener('timeupdate', handleTimeUpdate);
    audio.addEventListener('durationchange', handleDurationChange);
    audio.addEventListener('ended', handleEnded);

    return () => {
      audio.removeEventListener('timeupdate', handleTimeUpdate);
      audio.removeEventListener('durationchange', handleDurationChange);
      audio.removeEventListener('ended', handleEnded);
    };
  }, []);

  // ì¬ìƒ/ì¼ì‹œì •ì§€
  const togglePlayPause = async () => {
    if (!audioRef.current) return;

    // ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ TTS ìƒì„± í›„ ì¬ìƒ
    if (!audioUrl && !isGeneratingTTS) {
      await generateTTS();
      return;
    }

    // ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ ì¬ìƒ/ì¼ì‹œì •ì§€
    if (audioUrl) {
      if (isPlaying) {
        audioRef.current.pause();
      } else {
        audioRef.current.play();
      }
      setIsPlaying(!isPlaying);
    }
  };

  // ì§„í–‰ë¥  í´ë¦­
  const handleProgressClick = (event: React.MouseEvent<HTMLDivElement>) => {
    if (!audioRef.current) return;
    
    const rect = event.currentTarget.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const percentage = x / rect.width;
    const newTime = percentage * duration;
    
    audioRef.current.currentTime = newTime;
    setCurrentTime(newTime);
  };

  // ìŒì†Œê±° í† ê¸€
  const toggleMute = () => {
    if (!audioRef.current) return;
    
    const newMuted = !isMuted;
    setIsMuted(newMuted);
    audioRef.current.muted = newMuted;
  };

  // ğŸ™ï¸ Neural2 ê¸°ë°˜ TTS ìƒì„± (ìš°ì„ ìˆœìœ„) + í´ë°±
  const generateTTS = async () => {
    if (!chapter.text || isGeneratingTTS) return;

    setIsGeneratingTTS(true);
    setTtsError(null);

    try {
      console.log('ğŸ™ï¸ Neural2 TTS ìƒì„± ì‹œì‘:', { 
        chapterId: chapter.id, 
        textLength: chapter.text.length,
        language: chapter.language || 'ko'
      });

      // 1ï¸âƒ£ Neural2 TTS ì‹œë„ (ìš°ì„ ìˆœìœ„)
      const neural2Result = await neural2TTS.generateAudio({
        text: chapter.text,
        language: chapter.language || 'ko',
        chapterId: String(chapter.id),
        locationName: locationName,
        priority: 'normal'
      });

      if (neural2Result.success && neural2Result.audioUrl) {
        setAudioUrl(neural2Result.audioUrl);
        
        // ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì—…ë°ì´íŠ¸ëœ ì±•í„° ì •ë³´ ì „ë‹¬
        if (onChapterUpdate) {
          onChapterUpdate({
            ...chapter,
            audioUrl: neural2Result.audioUrl,
            isGeneratingTTS: false,
            ttsError: undefined
          });
        }

        console.log('âœ… Neural2 TTS ìƒì„± ì™„ë£Œ:', { 
          chapterId: chapter.id,
          isCached: neural2Result.cached,
          audioUrlType: neural2Result.audioUrl.startsWith('data:') ? 'base64' : 'url'
        });

        // ìƒì„± ì™„ë£Œ í›„ ìë™ ì¬ìƒ
        setTimeout(() => {
          if (audioRef.current) {
            audioRef.current.play();
            setIsPlaying(true);
          }
        }, 100);

        return; // Neural2 ì„±ê³µì‹œ ì—¬ê¸°ì„œ ì¢…ë£Œ
      }

      // 2ï¸âƒ£ Neural2 ì‹¤íŒ¨ì‹œ ê³ ê¸‰ TTS í´ë°±
      console.log('âš ï¸ Neural2 ì‹¤íŒ¨, ê³ ê¸‰ TTS í´ë°± ì‹œë„:', neural2Result.error);
      
      const advancedResult = await advancedTTSService.generatePersonalityTTS({
        text: chapter.text,
        language: chapter.language || 'ko-KR',
        userPersonality: chapter.personality || 'agreeableness',
        guide_id: guideId,
        locationName: locationName
      });

      if (advancedResult.success && advancedResult.audioData) {
        // Base64 ì˜¤ë””ì˜¤ë¥¼ Blob URLë¡œ ë³€í™˜
        const audioBlob = new Blob(
          [Uint8Array.from(atob(advancedResult.audioData), c => c.charCodeAt(0))], 
          { type: advancedResult.mimeType || 'audio/mpeg' }
        );
        const newAudioUrl = URL.createObjectURL(audioBlob);
        
        setAudioUrl(newAudioUrl);
        
        if (onChapterUpdate) {
          onChapterUpdate({
            ...chapter,
            audioUrl: newAudioUrl,
            isGeneratingTTS: false,
            ttsError: undefined
          });
        }

        console.log('âœ… ê³ ê¸‰ TTS í´ë°± ì™„ë£Œ:', { 
          chapterId: chapter.id,
          personality: advancedResult.personalityInfo?.appliedPersonality
        });

        setTimeout(() => {
          if (audioRef.current) {
            audioRef.current.play();
            setIsPlaying(true);
          }
        }, 100);

      } else {
        throw new Error(advancedResult.error || neural2Result.error || 'TTS ìƒì„± ì‹¤íŒ¨');
      }

    } catch (error) {
      console.error('âŒ TTS ìƒì„± ì™„ì „ ì‹¤íŒ¨:', error);
      const errorMessage = error instanceof Error ? error.message : String(t('audio.unknown_error') || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      setTtsError(errorMessage);
      
      if (onChapterUpdate) {
        onChapterUpdate({
          ...chapter,
          isGeneratingTTS: false,
          ttsError: errorMessage
        });
      }
    } finally {
      setIsGeneratingTTS(false);
    }
  };

  // ì˜¤ë””ì˜¤ URLì´ ë³€ê²½ë˜ë©´ ì˜¤ë””ì˜¤ ìš”ì†Œ ì—…ë°ì´íŠ¸
  useEffect(() => {
    if (audioRef.current && audioUrl) {
      audioRef.current.src = audioUrl;
      audioRef.current.load();
    }
  }, [audioUrl]);

  return (
    <div className={`space-y-3 ${className}`}>
      <audio ref={audioRef} preload="metadata" />
      
      {/* í†µí•© ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ */}
      <div className="flex items-center gap-3">
        {/* ì¬ìƒ/ì¼ì‹œì •ì§€ ë²„íŠ¼ */}
        <button
          onClick={togglePlayPause}
          disabled={isGeneratingTTS}
          className="w-8 h-8 bg-black text-white rounded-full flex items-center justify-center hover:bg-gray-800 transition-colors flex-shrink-0 disabled:bg-gray-400"
          aria-label={isGeneratingTTS ? String(t('audio.generating') || 'TTS ìƒì„± ì¤‘') : isPlaying ? String(t('audio.pause') || 'ì¼ì‹œì •ì§€') : String(t('audio.play') || 'ì¬ìƒ')}
        >
          {isGeneratingTTS ? (
            <Loader2 className="w-4 h-4 animate-spin" />
          ) : isPlaying ? (
            <Pause className="w-4 h-4" />
          ) : (
            <Play className="w-4 h-4 ml-0.5" />
          )}
        </button>

        {/* ì§„í–‰ë¥  ë°” */}
        <div className="flex-1 min-w-0">
          <div
            className="relative h-1.5 bg-gray-200 rounded-full cursor-pointer"
            onClick={handleProgressClick}
          >
            <div
              className="absolute top-0 left-0 h-full bg-black rounded-full"
              style={{ width: duration > 0 ? `${(currentTime / duration) * 100}%` : '0%' }}
            />
          </div>
          <div className="flex justify-between text-xs text-gray-500 mt-1">
            <span>{formatTime(currentTime)}</span>
            <span>{isGeneratingTTS ? 'TTS ìƒì„± ì¤‘...' : formatTime(duration)}</span>
          </div>
        </div>

        {/* ë³¼ë¥¨ */}
        <button
          onClick={toggleMute}
          disabled={!audioUrl}
          className="p-1 text-gray-600 hover:text-gray-900 transition-colors flex-shrink-0 disabled:text-gray-300"
          aria-label={isMuted ? 'ìŒì†Œê±° í•´ì œ' : 'ìŒì†Œê±°'}
        >
          {isMuted ? <VolumeX className="w-4 h-4" /> : <Volume2 className="w-4 h-4" />}
        </button>

        {/* ì¬ìƒì„± ë²„íŠ¼ (ì˜¤ë””ì˜¤ê°€ ìˆì„ ë•Œë§Œ) */}
        {audioUrl && (
          <button
            onClick={generateTTS}
            disabled={isGeneratingTTS}
            className="p-1 text-blue-600 hover:text-blue-800 transition-colors flex-shrink-0 disabled:text-gray-400"
            aria-label="TTS ì¬ìƒì„±"
            title="ìƒˆë¡œìš´ ìŒì„±ìœ¼ë¡œ ì¬ìƒì„±"
          >
            {isGeneratingTTS ? (
              <Loader2 className="w-4 h-4 animate-spin" />
            ) : (
              <Mic className="w-4 h-4" />
            )}
          </button>
        )}
      </div>
      
      {/* ì—ëŸ¬ í‘œì‹œ */}
      {ttsError && (
        <div className="text-red-600 text-sm bg-red-50 p-2 rounded">
          {ttsError}
        </div>
      )}
    </div>
  );
};

export default ChapterAudioPlayer;